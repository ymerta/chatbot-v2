---
title: Netmerian Bot V2
emoji: ğŸ”¥
colorFrom: gray
colorTo: purple
sdk: docker
pinned: false
---

# ğŸ¤– Netmerian Bot V2

Netmera iÃ§in geliÅŸtirilmiÅŸ akÄ±llÄ± chatbot sistemi. LangGraph kullanarak multi-step reasoning ve LangSmith ile comprehensive evaluation sistemi.

## ğŸš€ Ã–zellikler

- **Hybrid Retrieval**: FAISS + BM25 + Fuzzy Search kombinasyonu
- **Multi-language Support**: TÃ¼rkÃ§e ve Ä°ngilizce desteÄŸi
- **LangGraph Integration**: AkÄ±llÄ± conversation flow yÃ¶netimi
- **LangSmith Evaluation**: Comprehensive performance tracking
- **Real-time Analytics**: DetaylÄ± performance raporlarÄ±

## ğŸ“‹ Kurulum

### 1. Dependencies
```bash
pip install -r requirements.txt
```

### 2. Environment Setup
```bash
cp evaluation.env.example evaluation.env
# API key'lerinizi evaluation.env dosyasÄ±na ekleyin
```

### 3. Data Preparation
```bash
python src/index_build.py  # Embeddings oluÅŸtur
```

## ğŸ¯ KullanÄ±m

### Chatbot'u Ã‡alÄ±ÅŸtÄ±r
```bash
streamlit run app.py
```

### Evaluation Sistemi

#### Quick Setup
```bash
python setup_evaluation.py
```

#### Evaluation Ã‡alÄ±ÅŸtÄ±r
```bash
# Tek dataset
python evaluate_chatbot.py --dataset netmera-basic-qa

# TÃ¼m dataset'ler
python evaluate_chatbot.py --dataset all

# Custom experiment
python evaluate_chatbot.py --dataset netmera-advanced-qa --experiment my_test
```

#### Reports OluÅŸtur
```bash
# Son 7 gÃ¼nÃ¼n evaluations
python -m src.evaluation.reporting --recent 7

# Belirli experiments
python -m src.evaluation.reporting --experiments exp1 exp2 exp3
```

## ğŸ“Š Evaluation Datasets

Sistem Ã¼Ã§ farklÄ± dataset kullanÄ±r:

1. **netmera-basic-qa**: Temel Netmera Ã¶zellikleri (~20 examples)
2. **netmera-advanced-qa**: Teknik detaylar ve troubleshooting (~20 examples)  
3. **netmera-chat-scenarios**: Multi-turn konuÅŸmalar (~5 scenarios)

## ğŸ” Evaluation Metrics

- **Accuracy (30%)**: Teknik doÄŸruluk ve Netmera terminolojisi
- **Completeness (25%)**: CevaplarÄ±n kapsamlÄ±lÄ±ÄŸÄ±
- **Helpfulness (25%)**: KullanÄ±cÄ± iÃ§in pratik deÄŸer
- **Language Consistency (20%)**: Dil tutarlÄ±lÄ±ÄŸÄ±

## ğŸ“ˆ Performance Benchmarks

| Metric | Excellent | Good | Acceptable |
|--------|-----------|------|------------|
| Accuracy | â‰¥0.90 | â‰¥0.75 | â‰¥0.60 |
| Completeness | â‰¥0.85 | â‰¥0.70 | â‰¥0.55 |
| Helpfulness | â‰¥0.80 | â‰¥0.65 | â‰¥0.50 |

## ğŸ› ï¸ GeliÅŸtirme

### Demo Ã‡alÄ±ÅŸtÄ±r
```bash
python run_evaluation_demo.py
```

### Custom Evaluator Ekle
```python
from langsmith.schemas import Run, Example

def custom_evaluator(run: Run, example: Example) -> dict:
    # Custom evaluation logic
    return {"key": "custom_metric", "score": score, "reason": reason}
```

## ğŸ“š DokÃ¼mantasyon

- **Evaluation System**: [EVALUATION_README.md](EVALUATION_README.md)
- **API Reference**: Kod iÃ§i dokÃ¼mantasyon
- **LangSmith Dashboard**: https://smith.langchain.com/

## ğŸ¤ KatkÄ±da Bulunma

1. Yeni evaluation scenarios ekleyin
2. Custom evaluators geliÅŸtirin  
3. Performance optimizasyonlarÄ± yapÄ±n
4. Documentation'Ä± geliÅŸtirin

## ğŸ”— Links

- **LangSmith**: https://smith.langchain.com/
- **Netmera Docs**: https://user.netmera.com/
- **HuggingFace Space**: https://huggingface.co/docs/hub/spaces-config-reference
