#!/usr/bin/env python3
"""
Debug Failed Queries - Retrieval problemi analizi
BaÅŸarÄ±sÄ±z sorgularÄ± analiz edip retrieval optimizasyonu yapma
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Any

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_query_retrieval(query: str, expected_content: str = None) -> Dict[str, Any]:
    """Tek bir sorgunun retrieval performansÄ±nÄ± test et"""
    try:
        from config import FAISS_STORE_PATH
        from langchain_openai import OpenAIEmbeddings
        from langchain_community.vectorstores import FAISS
        from retrievers.hybrid import HybridRetriever
        
        # FAISS store'u yÃ¼kle
        emb = OpenAIEmbeddings()
        vs = FAISS.load_local(FAISS_STORE_PATH, emb, allow_dangerous_deserialization=True)
        docs = vs.docstore._dict
        
        # Corpus hazÄ±rla
        corpus_texts = [d.page_content for d in docs.values()]
        corpus_meta = [d.metadata for d in docs.values()]
        
        # Hybrid retriever oluÅŸtur
        retriever = HybridRetriever(corpus_texts, corpus_meta)
        
        # Query'yi test et
        print(f"\nğŸ” Testing query: '{query}'")
        results = retriever.retrieve(query, k=6)
        
        analysis = {
            "query": query,
            "total_results": len(results),
            "results": results,
            "top_score": results[0]["score"] if results else 0,
            "retrieval_quality": "good" if results and results[0]["score"] > 0.5 else "poor"
        }
        
        # SonuÃ§larÄ± yazdÄ±r
        print(f"ğŸ“Š Total results: {len(results)}")
        if results:
            print(f"ğŸ† Top score: {results[0]['score']:.3f}")
            print(f"ğŸ“„ Top result preview: {results[0]['text'][:200]}...")
            
            if expected_content:
                found_expected = any(expected_content.lower() in result['text'].lower() 
                                   for result in results)
                analysis["found_expected"] = found_expected
                print(f"ğŸ¯ Expected content found: {found_expected}")
        else:
            print("âŒ No results found!")
            
        return analysis
        
    except Exception as e:
        print(f"âŒ Error testing query: {e}")
        return {"query": query, "error": str(e)}

def test_problematic_queries():
    """Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ndeki problemli sorgularÄ± test et"""
    
    test_cases = [
        {
            "query": "Push mesaj boyutu limitini aÅŸtÄ±m hatasÄ± alÄ±yorum",
            "expected": ["push", "limit", "boyut", "size", "payload"],
            "category": "error_handling"
        },
        {
            "query": "IP adresim engellenmiÅŸ, ne yapabilirim?",
            "expected": ["ip", "blocked", "engel", "whitelist"],
            "category": "network_issues"
        },
        {
            "query": "Integrated Modules Via Integration Short Url Consent Requests",
            "expected": ["integration", "module", "consent", "url"],
            "category": "technical_integration"
        },
        {
            "query": "Email Delivery Onboarding",
            "expected": ["email", "delivery", "onboarding"],
            "category": "email_setup"
        }
    ]
    
    print("ğŸ§ª Testing Problematic Queries")
    print("=" * 50)
    
    results = []
    for test_case in test_cases:
        result = test_query_retrieval(test_case["query"])
        result.update(test_case)
        results.append(result)
        
        # KÄ±sa analiz
        if result.get("total_results", 0) == 0:
            print(f"ğŸ”´ FAILED: No results for '{test_case['query']}'")
        elif result.get("top_score", 0) < 0.3:
            print(f"ğŸŸ¡ WEAK: Low confidence for '{test_case['query']}'")
        else:
            print(f"ğŸŸ¢ OK: Good results for '{test_case['query']}'")
    
    return results

def analyze_retrieval_gaps():
    """Retrieval sistemindeki boÅŸluklarÄ± analiz et"""
    print("\nğŸ” Analyzing Retrieval System Gaps")
    print("=" * 50)
    
    # Common failure patterns
    failure_patterns = [
        "TÃ¼rkÃ§e error messages",
        "Network/IP related issues", 
        "Specific error codes",
        "Integration module names",
        "Email delivery specifics"
    ]
    
    recommendations = []
    
    for pattern in failure_patterns:
        print(f"\nğŸ“‹ Pattern: {pattern}")
        
        if "TÃ¼rkÃ§e" in pattern:
            print("   ğŸ’¡ Recommendation: Improve Turkish-English query translation")
            recommendations.append("enhance_turkish_translation")
            
        elif "Network" in pattern:
            print("   ğŸ’¡ Recommendation: Add network troubleshooting docs")
            recommendations.append("add_network_docs")
            
        elif "error codes" in pattern:
            print("   ğŸ’¡ Recommendation: Create error code mapping")
            recommendations.append("create_error_mapping")
            
        elif "Integration" in pattern:
            print("   ğŸ’¡ Recommendation: Improve technical term matching")
            recommendations.append("improve_technical_matching")
            
        elif "Email" in pattern:
            print("   ğŸ’¡ Recommendation: Enhance email-specific retrieval")
            recommendations.append("enhance_email_retrieval")
    
    return recommendations

def suggest_optimizations(test_results: List[Dict], recommendations: List[str]):
    """Somut optimizasyon Ã¶nerileri"""
    print("\nğŸš€ Optimization Recommendations")
    print("=" * 50)
    
    # 1. Retrieval optimizations
    print("\n1ï¸âƒ£ Retrieval Optimizations:")
    
    failed_queries = [r for r in test_results if r.get("total_results", 0) == 0]
    weak_queries = [r for r in test_results if 0 < r.get("top_score", 0) < 0.3]
    
    if failed_queries:
        print(f"   âŒ {len(failed_queries)} queries returned no results")
        print("   ğŸ’¡ Solution: Lower similarity threshold or expand search")
        
    if weak_queries:
        print(f"   ğŸŸ¡ {len(weak_queries)} queries had weak relevance")
        print("   ğŸ’¡ Solution: Adjust BM25/FAISS weights or improve chunking")
    
    # 2. Content gaps
    print("\n2ï¸âƒ£ Content Gap Solutions:")
    if "add_network_docs" in recommendations:
        print("   ğŸŒ Add network troubleshooting documentation")
        
    if "create_error_mapping" in recommendations:
        print("   ğŸ”¢ Create error code to solution mapping")
        
    if "enhance_email_retrieval" in recommendations:
        print("   ğŸ“§ Improve email delivery documentation coverage")
    
    # 3. Technical improvements
    print("\n3ï¸âƒ£ Technical Improvements:")
    if "enhance_turkish_translation" in recommendations:
        print("   ğŸ‡¹ğŸ‡· Improve Turkish query preprocessing")
        
    if "improve_technical_matching" in recommendations:
        print("   ğŸ”§ Add technical term synonyms and expansions")
    
    # 4. Immediate actions
    print("\n4ï¸âƒ£ Immediate Actions:")
    print("   ğŸ“ˆ Reduce similarity threshold from 0.5 to 0.3")
    print("   ğŸ”„ Increase retrieval results from 6 to 10")
    print("   ğŸ¯ Add query expansion for technical terms")
    print("   ğŸ“ Improve chunk metadata for better filtering")

def main():
    """Ana debug function"""
    print("ğŸ”§ Netmera Chatbot - Failed Query Analysis")
    print("=" * 60)
    
    # Environment check
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEY not found")
        return
    
    try:
        # 1. Test problematic queries
        test_results = test_problematic_queries()
        
        # 2. Analyze gaps
        recommendations = analyze_retrieval_gaps()
        
        # 3. Suggest optimizations
        suggest_optimizations(test_results, recommendations)
        
        # 4. Summary
        print(f"\nğŸ“‹ Summary:")
        total_tests = len(test_results)
        failed_tests = len([r for r in test_results if r.get("total_results", 0) == 0])
        success_rate = ((total_tests - failed_tests) / total_tests) * 100
        
        print(f"   Tests run: {total_tests}")
        print(f"   Failed: {failed_tests}")
        print(f"   Success rate: {success_rate:.1f}%")
        
        if success_rate < 80:
            print(f"   ğŸ”´ Retrieval needs optimization!")
        elif success_rate < 90:
            print(f"   ğŸŸ¡ Retrieval could be improved")
        else:
            print(f"   ğŸŸ¢ Retrieval performing well")
            
    except Exception as e:
        print(f"âŒ Analysis failed: {e}")

if __name__ == "__main__":
    main()
